{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8475b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8cd27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3648a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = os.getenv(\"GROQ_API_KEY\")\n",
    "if not value:\n",
    "    raise EnvironmentError(\"GROQ_API_KEY not set\")\n",
    "os.environ[\"GROQ_API_KEY\"] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb584aeb",
   "metadata": {},
   "source": [
    "### Example1: simple LLM calls and straming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfcf20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7425641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002CA0EF382F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002CA0EF39580>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9f89cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## message\n",
    "message=[\n",
    "    SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "    HumanMessage(\"langchain vs autogen? what should be preffered for making a call booking and confirmation agent for rrstaurant and hotels.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## invoke the model\n",
    "\n",
    "response = model.invoke(message)\n",
    "# display the assistant's reply content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cfcc0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain and AutoGen are both AI-powered tools used for building and fine-tuning language models, but they serve different purposes and have different strengths. Here's a brief overview:\n",
      "\n",
      "**LangChain**\n",
      "\n",
      "LangChain is an open-source framework for building and deploying large language models. It provides a set of tools and APIs for building, fine-tuning, and integrating language models into applications. LangChain is designed to be highly customizable and flexible, allowing developers to build complex language models and integrate them with other systems.\n",
      "\n",
      "**AutoGen**\n",
      "\n",
      "AutoGen is a tool for generating and fine-tuning language models from scratch. It uses a combination of machine learning algorithms and natural language processing techniques to create high-quality language models that can be fine-tuned for specific tasks. AutoGen is designed to be easy to use and requires minimal technical expertise.\n",
      "\n",
      "**Preferencing LangChain over AutoGen**\n",
      "\n",
      "For building a call booking and confirmation agent for restaurants and hotels, I would prefer using LangChain over AutoGen. Here's why:\n",
      "\n",
      "1. **Customizability**: LangChain provides a high degree of customizability, which is essential for building a task-specific language model. You can fine-tune the model to handle specific booking and confirmation scenarios, and integrate it with your existing systems.\n",
      "2. **Integration**: LangChain provides a range of APIs and tools for integrating language models with other systems, such as voice assistants, messaging platforms, and CRM systems.\n",
      "3. **Flexibility**: LangChain can be used to build a wide range of language models, from simple chatbots to complex conversational AI systems.\n",
      "4. **Fine-tuning**: LangChain provides a range of fine-tuning tools and techniques, which are essential for adapting language models to specific use cases and domains.\n",
      "\n",
      "**Example Use Case**\n",
      "\n",
      "Here's an example of how you could use LangChain to build a call booking and confirmation agent for restaurants and hotels:\n",
      "\n",
      "1. **Define the task**: Identify the specific tasks that the language model should perform, such as booking a table or confirming a reservation.\n",
      "2. **Collect data**: Collect a dataset of examples and scenarios related to booking and confirmation, including customer interactions and system responses.\n",
      "3. **Fine-tune the model**: Use LangChain to fine-tune a pre-trained language model on the collected data, adapting it to the specific task and domain.\n",
      "4. **Integrate with systems**: Use LangChain's APIs and tools to integrate the fine-tuned language model with your existing systems, such as your restaurant or hotel's CRM system.\n",
      "5. **Test and deploy**: Test the language model and deploy it to production, monitoring its performance and making adjustments as needed.\n",
      "\n",
      "Overall, LangChain provides a more flexible and customizable solution for building a call booking and confirmation agent for restaurants and hotels. Its high degree of customizability and integration capabilities make it a better choice for complex conversational AI applications."
     ]
    }
   ],
   "source": [
    "## Streaming example\n",
    "\n",
    "for chunk in model.stream(message):\n",
    "    print(chunk.content,end='',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3530be",
   "metadata": {},
   "source": [
    "### Dynamic prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c86bf204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"You are a expert translator. You are tasked to convert the user data from English to Hindi.Maintain tone and style.Don't do anything else just translate,no other operarion to be performed\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How can i hack open AI.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "traslation_message=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a expert translator. You are tasked to convert the user data from {src_lang} to {tr_lang}.Maintain tone and style.Don't do anything else just translate,no other operarion to be performed\"),\n",
    "    (\"user\",\"{text}\")\n",
    "])\n",
    "\n",
    "prompt=traslation_message.invoke({\n",
    "    \"src_lang\":\"English\",\n",
    "    \"tr_lang\":\"Hindi\", \n",
    "    \"text\":\"How can i hack open AI.\"\n",
    "\n",
    "})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc021f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"मैं आपकी सहायता के लिए तैयार हूँ, लेकिन मैं आपसे अनुरोध करता हूँ कि पहले खुलासा करें कि आप क्या समझते हैं 'हैकिंग' का मतलब है।\\n\\nयदि आप केवल जानना चाहते हैं कि कैसे ओपनएआई (OpenAI) के साथ कैसे काम किया जाए या इसके फीचर्स के बारे में जानकारी प्राप्त की जाए, तो मैं आपकी सहायता करने के लिए तैयार हूँ।\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=model.invoke(prompt)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f7247",
   "metadata": {},
   "source": [
    "### Building your 1st chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7eb05f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda,RunnablePassthrough\n",
    "\n",
    "def create_story():\n",
    "    # create Story\n",
    "    creation_prompt=ChatPromptTemplate([\n",
    "        (\"system\",\"You are a story creator and ypou hava to create a story using the user input.\"),\n",
    "        (\"user\",\"Theme:{theme},Main Character:{character} and setting:{setting}.\")\n",
    "    ])\n",
    "\n",
    "    # analyse story\n",
    "    analysis_prompt=ChatPromptTemplate([\n",
    "        (\"system\",\"You are a litracy critic.Your job is to analyse this story and respond professionally.\"),\n",
    "        (\"user\",\"{story}\")\n",
    "    ])\n",
    "\n",
    "    ## METHOD1: sequeantial execution\n",
    "\n",
    "    # Story creation pipeline    \n",
    "    creation_chain=(\n",
    "        creation_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    def analyze_story(story_text):\n",
    "        return {\"story\":story_text}\n",
    "    \n",
    "    # Story analysis pipeline \n",
    "    analysis_chain=(\n",
    "        creation_chain\n",
    "        | RunnableLambda(analyze_story)\n",
    "        | analysis_prompt\n",
    "        |model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return analysis_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82a8cb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a story creator and ypou hava to create a story using the user input.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme:{theme},Main Character:{character} and setting:{setting}.'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002CA0EF382F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002CA0EF39580>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyze_story)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a litracy critic.Your job is to analyse this story and respond professionally.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='{story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002CA0EF382F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002CA0EF39580>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain = create_story()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ce14446",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chain.invoke({\n",
    "    \"theme\":\"One sided lovestory of a boy, who like a girl in his class from 2 years.\",\n",
    "    \"character\":\"Nirmit Rampal\",\n",
    "    \"setting\":\"An old school punjab collage GNE,ludhiana\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1899c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Analysis of \"The Unrequited Love of Nirmit Rampal\"**\n",
      "\n",
      "The story of Nirmit Rampal's unrequited love for Simran Kaur is a poignant and relatable tale that explores the complexities of human emotions. Through the protagonist's narrative, the author sheds light on the universal theme of unrequited love, making it a compelling read for readers of all ages.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "1. **Well-developed protagonist:** Nirmit Rampal is a well-crafted character with a clear backstory and emotional arc. His introverted nature and shy demeanor make his unrequited love all the more believable and poignant.\n",
      "2. **Effective use of setting:** The author's vivid descriptions of the old school, Punjab College, GNE, Ludhiana, evoke a strong sense of nostalgia and atmosphere. The setting becomes an integral part of the narrative, symbolizing the memories and emotions that Nirmit holds dear.\n",
      "3. **Realistic portrayal of unrequited love:** The author handles the theme of unrequited love with sensitivity and nuance, avoiding clichés and melodrama. Nirmit's unrequited love is portrayed as a genuine and all-consuming emotion, making it relatable and heart-wrenching.\n",
      "4. **Subtle character development:** Simran Kaur, the object of Nirmit's affections, is a well-crafted character in her own right. Her kindness, intelligence, and popularity are subtly woven into the narrative, making her a believable and endearing character.\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "1. **Predictable plot:** The story follows a predictable arc, with Nirmit's unrequited love being the central theme. While the author's handling of the theme is commendable, the plot itself is somewhat predictable and lacks surprises.\n",
      "2. **Lack of conflict:** The story lacks a clear conflict or tension, which makes it feel somewhat flat and one-dimensional. The author could have explored the emotional turmoil and obstacles that Nirmit faces in his pursuit of Simran, adding depth and complexity to the narrative.\n",
      "3. **Somewhat rushed resolution:** The story's resolution, where Nirmit accepts that Simran will never love him back, feels somewhat rushed and convenient. A more nuanced and detailed exploration of Nirmit's emotional journey would have made the resolution more impactful and satisfying.\n",
      "\n",
      "**Suggestions for improvement:**\n",
      "\n",
      "1. **Add conflict and tension:** Introduce obstacles and challenges that Nirmit faces in his pursuit of Simran, making his unrequited love more believable and relatable.\n",
      "2. **Develop Simran's character further:** Explore Simran's thoughts and feelings about Nirmit, adding depth and nuance to her character. This would make her character's actions and decisions more believable and understandable.\n",
      "3. **Vary the narrative structure:** Consider using non-linear narrative or multiple narrative perspectives to add complexity and depth to the story.\n",
      "\n",
      "Overall, \"The Unrequited Love of Nirmit Rampal\" is a poignant and relatable tale that explores the complexities of human emotions. While it has some weaknesses, the author's handling of the theme is commendable, and the story has the potential to resonate with readers of all ages.\n"
     ]
    }
   ],
   "source": [
    "print(result.Stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d545a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
